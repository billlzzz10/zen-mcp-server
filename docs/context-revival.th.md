# Context Revival: ความทรงจำของ AI ที่อยู่เหนือขีดจำกัดบริบท

## ฟีเจอร์ที่ทรงพลังที่สุด: ฟื้นบริบทหลังรีเซ็ต

Zen MCP Server มีระบบสานต่อบทสนทนาที่ทำให้รู้สึกว่าข้ามขีดจำกัดบริบทของ Claude ได้จริง

## ระบบ Context Revival ทำงานอย่างไร

โมดูลจัดการความจำการสนทนา (`utils/conversation_memory.py`) สร้างสถาปัตยกรรมที่เชื่อมช่องว่างระหว่างความเป็น stateless ของ Claude และการร่วมมือแบบมีความจำถาวร (ภายใต้ข้อจำกัดที่ควบคุมได้)

### สถาปัตยกรรมเบื้องหลัง

1. **เก็บ thread ถาวร** – ทุกการสนทนาจะมี UUID เฉพาะเก็บไว้ในหน่วยความจำ
2. **สานต่อข้ามเครื่องมือ** – ทุกเครื่องมือใช้ `Continuation ID` เดียวกันเพื่อเริ่มต่อได้เหมือนเลขอ้างอิงอีเมล
3. **สร้างบริบทคืน** – แม้ Claude ถูกรีเซ็ต บทสนทนาเดิมยังอยู่ในความทรงจำของ MCP
4. **ดึงประวัติกลับ** – เมื่อสั่ง `continue` เซิร์ฟเวอร์จะประกอบประวัติทั้งหมดพร้อมไฟล์อ้างอิงให้โมเดลใหม่
5. **ส่งต่อบริบทเต็ม** – โมเดลอื่น (เช่น O3, Gemini) ได้รับบทสนทนาทั้งหมดที่เคยเกิดขึ้น
6. **ปลุกความเข้าใจ** – คำตอบของโมเดลนั้นทำให้ Claude “นึกได้” ว่าคุยอะไรกันไว้ก่อนหน้า

### กลยุทธ์จัดลำดับข้อมูลแบบสองชั้น

ระบบใช้แนวทาง **ใหม่ก่อนเสมอ (newest-first)** เพื่อรักษาบริบทให้ดีที่สุด:

**การจัดลำดับไฟล์**
- ไล่ย้อนจากบทสนทนาล่าสุดไปเก่าสุด
- ถ้าไฟล์เดียวกันถูกแชร์หลายครั้ง จะเก็บเวอร์ชันใหม่สุดเท่านั้น
- ช่วยให้ context ที่สำคัญสุดไม่ถูกตัดทิ้งเมื่อโทเคนจำกัด

**การจัดลำดับบทสนทนา**
- **Collect phase**: รวบรวมจากใหม่ไปเก่าเพื่อเลือกข้อมูลสำคัญก่อน
- **Presentation phase**: ย้อนกลับมาแสดงแบบลำดับเวลา เพื่อให้ LLM เข้าใจตามธรรมชาติ
- ถ้าโทเคนไม่พอ บทสนทนาเก่าจะถูกตัดก่อน

**ตัวอย่างสาธิต**

วิดีโอด้านล่างสาธิตการสานต่อด้วยพรอมต์ `continue with gemini...` และคำสั่ง `/continue`

- เราให้ Claude เลือกหนึ่ง แล้วใช้ `chat` กับ Gemini เพื่อสรุป
- Gemini ยืนยันคำตอบ จากนั้นใช้ `continuation` ถามเพิ่ม
- ต่อด้วย `/zen:continue (MCP)` เพื่อถามอีกครั้งใน thread เดิม

<div style="center">

[Chat With Gemini_web.webm](https://github.com/user-attachments/assets/37bd57ca-e8a6-42f7-b5fb-11de271e95db)

</div>

## ตัวอย่างจริงของ Context Revival

**เซสชัน 1: ก่อนบริบทรีเซ็ต**
คุณ: "ช่วยออกแบบระบบ RAG สำหรับแชตบอตฝ่ายซัพพอร์ต อยากผสาน vector embeddings กับ retrieval แบบเรียลไทม์ คิดอย่างลึกกับ zen โดยใช้ o3 หลังได้แผนละเอียด"

Claude: "ฉันจะวิเคราะห์ความต้องการเพื่อออกแบบสถาปัตยกรรม RAG"
- ใช้ [`thinkdeep`](../README.md#1-chat---general-development-chat--collaborative-thinking) ระดมไอเดีย
- Zen สร้าง thread: `abc123-def456-ghi789`
- Claude สรุปแผนให้ผู้ใช้

*(หลังจากนั้นบริบทของ Claude โดนย่อ/รีเซ็ตเพราะคุยยาว)*

**เซสชัน 2: หลังรีเซ็ตบริบท**
คุณ: "ต่อจากแผน RAG ที่คุยกับ O3 ที อยากโฟกัสด้านปรับแต่ง inference แบบเรียลไทม์"

- Claude ใช้ continuation ล่าสุด ส่งเฉพาะคำถามใหม่ (Zen จำรายละเอียดเดิมได้อยู่แล้ว)
- O3 ได้รับประวัติทั้งหมดจาก Zen
- O3 เห็นว่าก่อนหน้านี้คุยเรื่องฐานข้อมูลเวกเตอร์ กลยุทธ์ฝังข้อมูล ฯลฯ
- O3 สานต่อ: เสนอการทำ semantic caching ฯลฯ
- คำตอบของ O3 ทำให้ Claude เชื่อมเข้าฉากสนทนาก่อนสได้อีกครั้ง

Claude: "ยอดเยี่ยม! จากข้อเสนอของ O3 มาลงมือทำเลเยอร์ semantic caching ต่อ"

**สรุป:** ถึงบริบทของ Claude จะถูกลบ โมเดลอื่นช่วย “ย้ำความจำ” ได้ เพราะ Zen เก็บประวัติไว้ครบ

## ทำไมสิ่งนี้จึงสำคัญ

**ก่อนมี Zen MCP:** เมื่อบริบท Claude รีเซ็ต บทสนทนาที่ยาวหายหมด ต้องเริ่มใหม่หรือป้อนไฟล์ซ้ำ

**หลังใช้ Zen MCP:** Claude สามารถประสานงานโมเดลต่าง ๆ ได้หลายชั่วโมง เช่น
- **O3** ทำงานเหตุผลและดีบักเชิงตรรกะ
- **Gemini Pro** วิเคราะห์สถาปัตย์เชิงลึก
- **Flash** ตรวจสไตล์และฟอร์แมตเร็ว ๆ
- **Claude** เป็นผู้ควบคุมบทสนทนาพร้อมบริบทครบ

**จุดเปลี่ยน:** แม้ Claude จะลืม โมเดลอื่นก็เตือนให้จำบทสนทนาครั้งก่อน ๆ ได้ครบ

## การตั้งค่า

ค่าเริ่มต้นปรับได้ผ่าน `.env`:

```env
MAX_CONVERSATION_TURNS=20       # จำนวนรอบสูงสุด (ดีฟอลต์ 20)
CONVERSATION_TIMEOUT_HOURS=3    # เวลาหมดอายุ thread (ดีฟอลต์ 3 ชั่วโมง)
```

## ผลลัพธ์: การออเคสตรา AI อย่างแท้จริง

- บทสนทนาอยู่รอดแม้เกินขีดจำกัดบริบท
- โมเดลสามารถต่อยอดงานของกันและกันข้ามเซสชัน
- Claude คุมเวิร์กโฟลว์หลายขั้นตอนอย่างราบรื่น
- บริบทไม่เคยหายจริง เพียงถูกซ่อนชั่วคราว

**นี่คือระบบที่ใกล้เคียงกับการให้ Claude มีความจำถาวรสำหรับงานพัฒนาซับซ้อนที่สุด**
